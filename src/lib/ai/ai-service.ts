/**
 * AIæœåŠ¡ V4 - ç®€åŒ–é‡æ„ç‰ˆæœ¬
 * ä¸“æ³¨äºç¨³å®šæ€§å’Œå¯ç»´æŠ¤æ€§
 */

export interface AIMessage {
  role: 'system' | 'user' | 'assistant'
  content: string
}

export interface AIResponse {
  type: 'text' | 'plan' | 'error' | 'done'
  content: string
  plan?: ExecutionPlan
  conversationId: string
}

export interface ExecutionPlan {
  id: string
  title: string
  description: string
  steps: ExecutionStep[]
  createdAt: Date
}

export interface ExecutionStep {
  id: string
  type: 'create_markers' | 'create_chain' | 'message'
  name: string
  description: string
  args: any
  status: 'pending' | 'running' | 'completed' | 'failed'
}

/**
 * å¯¹è¯ç®¡ç†å™¨
 */
class ConversationManager {
  private conversations = new Map<string, AIMessage[]>()
  private systemPrompt: string

  constructor(systemPrompt: string) {
    this.systemPrompt = systemPrompt
  }

  createConversation(): string {
    const id = `conv_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
    this.conversations.set(id, [])
    return id
  }

  addMessage(conversationId: string, message: AIMessage): void {
    if (!this.conversations.has(conversationId)) {
      this.conversations.set(conversationId, [])
    }
    this.conversations.get(conversationId)!.push(message)
  }

  getMessages(conversationId: string): AIMessage[] {
    return [
      { role: 'system', content: this.systemPrompt },
      ...(this.conversations.get(conversationId) || [])
    ]
  }

  clearConversation(conversationId: string): void {
    this.conversations.delete(conversationId)
  }
}

/**
 * AIå¼•æ“ - ç®€åŒ–ç‰ˆæœ¬
 */
class AIEngine {
  private baseUrl: string
  private model: string

  constructor(baseUrl: string, model: string) {
    this.baseUrl = baseUrl
    this.model = model
  }

  async *generateStream(messages: AIMessage[]): AsyncGenerator<string> {
    try {
      console.log('ğŸ¤– è°ƒç”¨AIæ¨¡å‹:', this.model)
      
      const response = await fetch(`${this.baseUrl}/api/chat`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: this.model,
          messages,
          stream: true
        }),
        signal: AbortSignal.timeout(60000)
      })

      if (!response.ok) {
        throw new Error(`AIæœåŠ¡é”™è¯¯: ${response.status}`)
      }

      const reader = response.body?.getReader()
      if (!reader) {
        throw new Error('æ— æ³•è·å–å“åº”æµ')
      }

      const decoder = new TextDecoder()
      let buffer = ''

      try {
        while (true) {
          const { done, value } = await reader.read()
          if (done) break

          buffer += decoder.decode(value, { stream: true })
          const lines = buffer.split('\n')
          buffer = lines.pop() || ''

          for (const line of lines) {
            if (!line.trim()) continue
            
            try {
              const data = JSON.parse(line)
              if (data.message?.content) {
                yield data.message.content
              }
            } catch {
              // å¿½ç•¥è§£æé”™è¯¯
            }
          }
        }
      } finally {
        reader.releaseLock()
      }
    } catch (error) {
      console.error('âŒ AIå¼•æ“é”™è¯¯:', error)
      throw error
    }
  }
}

/**
 * è®¡åˆ’è§£æå™¨
 */
class PlanParser {
  static extractPlan(text: string): ExecutionPlan | null {
    try {
      // æŸ¥æ‰¾ <plan> æ ‡ç­¾
      const planMatch = text.match(/<plan>([\s\S]*?)<\/plan>/i)
      if (!planMatch) return null

      const planContent = planMatch[1].trim()
      const planData = JSON.parse(planContent)

      if (!planData.toolCalls || !Array.isArray(planData.toolCalls)) {
        return null
      }

      // è½¬æ¢ä¸ºæ‰§è¡Œæ­¥éª¤
      const steps: ExecutionStep[] = planData.toolCalls.map((tool: any, index: number) => ({
        id: `step_${index + 1}`,
        type: tool.name === 'create_marker_v2' ? 'create_markers' : 
              tool.name === 'create_travel_chain' ? 'create_chain' : 'message',
        name: tool.name,
        description: this.getStepDescription(tool),
        args: tool.args,
        status: 'pending' as const
      }))

      return {
        id: `plan_${Date.now()}`,
        title: planData.title || 'æ—…æ¸¸è®¡åˆ’',
        description: planData.description || 'ç”¨æˆ·å®šåˆ¶çš„æ—…æ¸¸è®¡åˆ’',
        steps,
        createdAt: new Date()
      }
    } catch (error) {
      console.error('è®¡åˆ’è§£æå¤±è´¥:', error)
      return null
    }
  }

  private static getStepDescription(tool: any): string {
    switch (tool.name) {
      case 'create_marker_v2':
        const placeCount = tool.args?.places?.length || 0
        return `åˆ›å»º ${placeCount} ä¸ªåœ°ç‚¹æ ‡è®°`
      case 'create_travel_chain':
        return `åˆ›å»ºè¡Œç¨‹é“¾: ${tool.args?.chainName || 'æœªå‘½å'}`
      default:
        return tool.name
    }
  }

  static filterThinking(text: string): string {
    // ç§»é™¤ <think> æ ‡ç­¾å†…å®¹
    return text.replace(/<think>[\s\S]*?<\/think>/gi, '').trim()
  }
}

/**
 * AIæœåŠ¡ä¸»ç±» - V4ç‰ˆæœ¬
 */
export class AIService {
  private aiEngine: AIEngine
  private conversationManager: ConversationManager
  private systemPrompt: string

  constructor() {
    const baseUrl = process.env.OLLAMA_URL || 'http://localhost:11434'
    const model = process.env.OLLAMA_MODEL || 'deepseek-r1:8b'
    
    this.systemPrompt = this.buildSystemPrompt()
    this.aiEngine = new AIEngine(baseUrl, model)
    this.conversationManager = new ConversationManager(this.systemPrompt)
  }

  private buildSystemPrompt(): string {
    return `ä½ æ˜¯æ—…æ¸¸è§„åˆ’åŠ©æ‰‹ï¼Œä¸“é—¨è´Ÿè´£åˆ†æç”¨æˆ·éœ€æ±‚å¹¶ç”Ÿæˆåœ°å›¾æ ‡è®°åˆ›å»ºè®¡åˆ’ã€‚

## æ ¸å¿ƒä»»åŠ¡
1. æ·±åº¦åˆ†æç”¨æˆ·çš„æ—…æ¸¸éœ€æ±‚
2. åŸºäºä½ çš„çŸ¥è¯†æ¨èåˆé€‚çš„åœ°ç‚¹
3. ç”Ÿæˆç»“æ„åŒ–çš„æ‰§è¡Œè®¡åˆ’ï¼Œä¾›å‰ç«¯å®æ—¶æ‰§è¡Œ

## è¾“å‡ºæ ¼å¼
<think>
[æ·±åº¦æ€è€ƒç”¨æˆ·éœ€æ±‚ï¼Œåˆ†ææ—…æ¸¸åå¥½ã€æ—¶é—´å®‰æ’ã€é¢„ç®—è€ƒè™‘ç­‰ï¼Œåˆ—å‡ºæ¨èåœ°ç‚¹å’Œç†ç”±]
</think>

<plan>
{
  "title": "è®¡åˆ’æ ‡é¢˜",
  "description": "è®¡åˆ’æè¿°",
  "toolCalls": [
    {
      "name": "create_marker_v2",
      "args": {
        "places": [
          {"name": "åœ°ç‚¹åç§°", "iconType": "landmark", "content": "è¯¦ç»†ä»‹ç»"}
        ]
      }
    }
  ]
}
</plan>

## å›¾æ ‡ç±»å‹
- landmark: åœ°æ ‡å»ºç­‘
- culture: åšç‰©é¦†ã€æ–‡åŒ–é—è¿¹
- natural: è‡ªç„¶æ™¯è§‚
- food: é¤å…ã€ç¾é£Ÿ
- shopping: è´­ç‰©åœºæ‰€
- activity: å¨±ä¹æ´»åŠ¨
- hotel: ä½å®¿
- park: å…¬å›­

é‡è¦ï¼šåªç”Ÿæˆè®¡åˆ’ï¼Œä¸æ‰§è¡Œå…·ä½“æ“ä½œã€‚`
  }

  /**
   * åˆ›å»ºæ–°å¯¹è¯
   */
  createConversation(): string {
    return this.conversationManager.createConversation()
  }

  /**
   * æµå¼å¤„ç†æ¶ˆæ¯
   */
  async *processMessageStream(
    message: string,
    conversationId: string
  ): AsyncGenerator<AIResponse> {
    try {
      console.log('ğŸ¤– å¤„ç†æ¶ˆæ¯:', message)

      // è·å–å¯¹è¯æ¶ˆæ¯
      const messages = this.conversationManager.getMessages(conversationId)
      messages.push({ role: 'user', content: message })

      let fullResponse = ''
      let isInThinkTag = false
      let isInPlanTag = false
      let planContent = ''

      // æµå¼ç”Ÿæˆ
      for await (const chunk of this.aiEngine.generateStream(messages)) {
        fullResponse += chunk

        // å¤„ç†æ€è€ƒæ ‡ç­¾
        if (chunk.includes('<think>')) {
          isInThinkTag = true
          continue
        }
        if (chunk.includes('</think>')) {
          isInThinkTag = false
          continue
        }
        if (isInThinkTag) {
          continue // è·³è¿‡æ€è€ƒå†…å®¹
        }

        // å¤„ç†è®¡åˆ’æ ‡ç­¾
        if (chunk.includes('<plan>')) {
          isInPlanTag = true
          planContent = ''
          continue
        }
        if (chunk.includes('</plan>')) {
          isInPlanTag = false
          
          // è§£æå¹¶å‘é€è®¡åˆ’
          const plan = PlanParser.extractPlan(`<plan>${planContent}</plan>`)
          if (plan) {
            yield {
              type: 'plan',
              content: 'å·²ç”Ÿæˆæ‰§è¡Œè®¡åˆ’',
              plan,
              conversationId
            }
          }
          continue
        }
        if (isInPlanTag) {
          planContent += chunk
          continue
        }

        // è¾“å‡ºæ­£å¸¸æ–‡æœ¬
        if (chunk.trim()) {
          yield {
            type: 'text',
            content: chunk,
            conversationId
          }
        }
      }

      // ä¿å­˜å¯¹è¯å†å²
      this.conversationManager.addMessage(conversationId, { role: 'user', content: message })
      this.conversationManager.addMessage(conversationId, { role: 'assistant', content: fullResponse })

      // å‘é€å®Œæˆä¿¡å·
      yield {
        type: 'done',
        content: '',
        conversationId
      }

    } catch (error) {
      console.error('âŒ å¤„ç†å¤±è´¥:', error)
      yield {
        type: 'error',
        content: `å¤„ç†å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`,
        conversationId
      }
    }
  }

  /**
   * æ¸…ç†å¯¹è¯
   */
  clearConversation(conversationId: string): void {
    this.conversationManager.clearConversation(conversationId)
  }

  /**
   * è·å–ç»Ÿè®¡ä¿¡æ¯
   */
  getStats() {
    return {
      model: process.env.OLLAMA_MODEL || 'deepseek-r1:8b',
      baseUrl: process.env.OLLAMA_URL || 'http://localhost:11434'
    }
  }
}